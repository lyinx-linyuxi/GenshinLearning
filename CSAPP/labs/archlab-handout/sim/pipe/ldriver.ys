#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-8, %rdx
	jl remainings
Loop1:
	mrmovq (%rdi), %r8
	mrmovq 8(%rdi), %r9
	rmmovq %r8, (%rsi)
	rmmovq %r9, 8(%rsi)	
	andq %r8, %r8
	jle test1
	iaddq $1, %rax
test1:
	andq %r9, %r9
	jle Loop2
	iaddq $1, %rax
Loop2:
	mrmovq 16(%rdi), %r8
	mrmovq 24(%rdi), %r9
	rmmovq %r8, 16(%rsi)
	rmmovq %r9, 24(%rsi)
	andq %r8, %r8
	jle test2
	iaddq $1, %rax
test2:
	andq %r9, %r9
	jle Loop3
	iaddq $1, %rax	
Loop3:
	mrmovq 32(%rdi), %r8
	mrmovq 40(%rdi), %r9
	rmmovq %r8, 32(%rsi)
	rmmovq %r9, 40(%rsi)
	andq %r8, %r8
	jle test3
	iaddq $1, %rax
test3:
	andq %r9, %r9
	jle Loop4
	iaddq $1, %rax	
Loop4:
	mrmovq 48(%rdi), %r8
	mrmovq 56(%rdi), %r9
	rmmovq %r8, 48(%rsi)
	rmmovq %r9, 56(%rsi)
	andq %r8, %r8
	jle test4
	iaddq $1, %rax
test4:
	andq %r9, %r9
	jle testE
	iaddq $1, %rax	
testE:
	iaddq $64, %rdi
	iaddq $64, %rsi
	iaddq $-8, %rdx
	jge Loop1

remainings:
	iaddq $8, %rdx
	je Done
	iaddq $-4, %rdx
	jge move4
	iaddq $2, %rdx
	jge move2
	jmp move1

move4:
	mrmovq (%rdi), %r8
	mrmovq 8(%rdi), %r9
	mrmovq 16(%rdi), %r10
	mrmovq 24(%rdi), %r11
	rmmovq %r8, (%rsi)
	rmmovq %r9, 8(%rsi)
	rmmovq %r10, 16(%rsi)
	rmmovq %r11, 24(%rsi)
	andq %r8, %r8
	jle m4a1
	iaddq $1, %rax
m4a1:
	andq %r9, %r9
	jle m4a2
	iaddq $1, %rax
m4a2:
	andq %r10, %r10
	jle m4a3
	iaddq $1, %rax
m4a3:
	andq %r11, %r11
	jle m4a4
	iaddq $1, %rax
m4a4:
	andq %rdx, %rdx
	je Done
	iaddq $32, %rdi
	iaddq $32, %rsi
	iaddq $-2, %rdx
	jge move2
	jmp move1

move2:
	mrmovq (%rdi), %r8
	mrmovq 8(%rdi), %r9
	rmmovq %r8, (%rsi)
	rmmovq %r9, 8(%rsi)
	andq %r8, %r8
	jle m2a1
	iaddq $1, %rax
m2a1:
	andq %r9, %r9
	jle m2a2
	iaddq $1, %rax
m2a2:
	andq %rdx, %rdx
	je Done
	iaddq $16, %rdi
	iaddq $16, %rsi
	jmp move1

move1:	
	mrmovq (%rdi), %r8
	rmmovq %r8, (%rsi)
	andq %r8, %r8
	jle Done
	iaddq $1, %rax
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad 2
	.quad -3
	.quad 4
	.quad 5
	.quad -6
	.quad 7
	.quad -8
	.quad -9
	.quad -10
	.quad -11
	.quad 12
	.quad 13
	.quad -14
	.quad -15
	.quad -16
	.quad -17
	.quad 18
	.quad -19
	.quad -20
	.quad -21
	.quad -22
	.quad 23
	.quad 24
	.quad 25
	.quad -26
	.quad 27
	.quad 28
	.quad -29
	.quad 30
	.quad 31
	.quad 32
	.quad -33
	.quad 34
	.quad -35
	.quad -36
	.quad 37
	.quad -38
	.quad 39
	.quad -40
	.quad -41
	.quad -42
	.quad -43
	.quad -44
	.quad 45
	.quad 46
	.quad -47
	.quad 48
	.quad 49
	.quad -50
	.quad -51
	.quad 52
	.quad 53
	.quad 54
	.quad -55
	.quad -56
	.quad -57
	.quad 58
	.quad 59
	.quad 60
	.quad 61
	.quad 62
	.quad 63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
